{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-02T21:45:24.620465Z",
     "start_time": "2025-12-02T21:45:24.588263Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('breast+cancer+wisconsin+diagnostic/wdbc.txt', header = None, engine = \"python\", sep = r\"\\s*,\\s*\")\n",
    "columns = [\"id\", \"diagnosis\",'radius_mean','texture_mean','perimeter_mean', 'area_mean', 'smoothness_mean','compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean','radius_se','texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "  'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "  'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst',\n",
    "   'fractal_dimension_worst']\n",
    "df.columns = columns\n",
    "df.to_csv('breast_cancer_data.csv',index=False)\n",
    "df.drop(\"id\",axis=1, inplace=True)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T21:45:30.027478Z",
     "start_time": "2025-12-02T21:45:30.021591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#data processing.\n",
    "data = df.copy()\n",
    "data[\"diagnosis\"] = data[\"diagnosis\"].map({'B': 0, 'M': 1})\n",
    "\n",
    "#splitting features from target variable.\n",
    "X = data.drop(\"diagnosis\", axis=1)\n",
    "Y = data[\"diagnosis\"]\n",
    "\n",
    "#making a transformer for scaling all numerical features.\n",
    "numerical_cols = X.columns.tolist()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', StandardScaler(), numerical_cols)])\n",
    "\n",
    "#partitions for train test split.\n",
    "partitions = [\n",
    "    (0.2, 0.8, \"20/80\"),\n",
    "    (0.5, 0.5, \"50/50\"),\n",
    "    (0.8, 0.2, \"80/20\")\n",
    "]"
   ],
   "id": "87466aab939a187d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T21:45:38.815113Z",
     "start_time": "2025-12-02T21:45:32.656164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "#code for cv, training and testing starts here.\n",
    "results = []\n",
    "for training_size, testing_size, partition_name in partitions:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Partition: {partition_name} (Train/Test)\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    current_partition_results = []\n",
    "    #doing three trials by looping 3 times.\n",
    "    for trial_number in range(3):\n",
    "        print(f\"Trial number: {trial_number+1}\")\n",
    "\n",
    "        #splitting data into training and testing and creating a pipeline for preprocessing and classification.\n",
    "        X_training, X_testing, Y_training, Y_testing = train_test_split(X, Y, test_size = testing_size, random_state = 42+trial_number,  stratify = Y)\n",
    "        xg_boost_pipeline = Pipeline([\n",
    "            ('Preprocessor', preprocessor),\n",
    "            ('classifier', XGBClassifier(random_state = 42+trial_number, eval_metric = 'logloss'))\n",
    "        ])\n",
    "\n",
    "        #hyperparameters\n",
    "        parameter_grid = {\n",
    "            'classifier__n_estimators': [100, 200],\n",
    "            'classifier__max_depth': [3, 4, 5],\n",
    "            'classifier__learning_rate': [0.1, 0.2],\n",
    "            'classifier__subsample': [0.8, 1.0],\n",
    "        }\n",
    "        #Tuning hyperparameters to find best model\n",
    "        grid_search = GridSearchCV(xg_boost_pipeline, parameter_grid, n_jobs=-1, cv=5, scoring='accuracy', verbose=0)\n",
    "        grid_search.fit(X_training, Y_training)\n",
    "        optimum_model = grid_search.best_estimator_\n",
    "\n",
    "        #getting label predictions from the best model.\n",
    "        training_prediction = optimum_model.predict(X_training)\n",
    "        testing_prediction = optimum_model.predict(X_testing)\n",
    "\n",
    "        #calculating accuracies\n",
    "        training_accuracy = accuracy_score(Y_training, training_prediction)\n",
    "        testing_accuracy = accuracy_score(Y_testing, testing_prediction)\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"training_Accuracy: {training_accuracy:.4f}\")\n",
    "        print(f\"testing_accuracy: {testing_accuracy:.4f}\")\n",
    "        print(f\"cv_accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        trial_result = {\n",
    "            \"Partition name\": partition_name,\n",
    "            \"Trial number\": trial_number+1,\n",
    "            \"Training accuracy\": training_accuracy,\n",
    "            \"Testing accuracy\": testing_accuracy,\n",
    "            \"Cross validation accuracy\":grid_search.best_score_,\n",
    "            \"Best parameters\":grid_search.best_params_\n",
    "        }\n",
    "        current_partition_results.append(trial_result)\n",
    "\n",
    "    #calculating average accuracy for training, cross validation and testing.\n",
    "    avg_training_accuracy = np.mean([result[\"Training accuracy\"] for result in current_partition_results])\n",
    "    avg_testing_accuracy = np.mean([result[\"Testing accuracy\"] for result in current_partition_results])\n",
    "    avg_cv_accuracy = np.mean([result[\"Cross validation accuracy\"] for result in current_partition_results])\n",
    "\n",
    "    average_accuracy_summary = {\n",
    "        \"Partition name\": partition_name,\n",
    "        \"Partition results\": current_partition_results,\n",
    "        \"Average training accuracy\": avg_training_accuracy,\n",
    "        \"Average testing accuracy\": avg_testing_accuracy,\n",
    "        \"Average cross validation accuracy\": avg_cv_accuracy,\n",
    "    }\n",
    "    results.append(average_accuracy_summary)"
   ],
   "id": "8aa6cd750810a30b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Partition: 20/80 (Train/Test)\n",
      "==================================================\n",
      "Trial number: 1\n",
      "Best Parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 3, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9759\n",
      "cv_accuracy: 0.9126\n",
      "Trial number: 2\n",
      "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9364\n",
      "cv_accuracy: 0.9206\n",
      "Trial number: 3\n",
      "Best Parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 3, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9452\n",
      "cv_accuracy: 0.9379\n",
      "\n",
      "==================================================\n",
      "Partition: 50/50 (Train/Test)\n",
      "==================================================\n",
      "Trial number: 1\n",
      "Best Parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9754\n",
      "cv_accuracy: 0.9612\n",
      "Trial number: 2\n",
      "Best Parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9719\n",
      "cv_accuracy: 0.9648\n",
      "Trial number: 3\n",
      "Best Parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9649\n",
      "cv_accuracy: 0.9578\n",
      "\n",
      "==================================================\n",
      "Partition: 80/20 (Train/Test)\n",
      "==================================================\n",
      "Trial number: 1\n",
      "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9737\n",
      "cv_accuracy: 0.9714\n",
      "Trial number: 2\n",
      "Best Parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 4, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9649\n",
      "cv_accuracy: 0.9670\n",
      "Trial number: 3\n",
      "Best Parameters: {'classifier__learning_rate': 0.2, 'classifier__max_depth': 3, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
      "training_Accuracy: 1.0000\n",
      "testing_accuracy: 0.9561\n",
      "cv_accuracy: 0.9692\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T21:45:38.825336Z",
     "start_time": "2025-12-02T21:45:38.820151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#printing final results and making a csv data table containing the results.\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Final summary - XGBoost on Breast Cancer Dataset\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Partition: {result['Partition name']}\")\n",
    "    print(f\"  Avg Train Accuracy: {result[\"Average training accuracy\"]:.4f}\")\n",
    "    print(f\"  Avg CV Accuracy: {result['Average cross validation accuracy']:.4f}\")\n",
    "    print(f\"  Avg Test Accuracy: {result['Average testing accuracy']:.4f}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "compiled_results = []\n",
    "for result in results:\n",
    "    for partition in result[\"Partition results\"]:\n",
    "        compiled_results.append(partition)\n",
    "\n",
    "xgboost_results_csv = pd.DataFrame(compiled_results)\n",
    "xgboost_results_csv.to_csv(\"xgboost_results.csv\", index=False)\n",
    "print(\"results saved to xgboost_results.csv successfully!\")"
   ],
   "id": "4cc55f337f504639",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Final summary - XGBoost on Breast Cancer Dataset\n",
      "============================================================\n",
      "Partition: 20/80\n",
      "  Avg Train Accuracy: 1.0000\n",
      "  Avg CV Accuracy: 0.9237\n",
      "  Avg Test Accuracy: 0.9525\n",
      "\n",
      "Partition: 50/50\n",
      "  Avg Train Accuracy: 1.0000\n",
      "  Avg CV Accuracy: 0.9613\n",
      "  Avg Test Accuracy: 0.9708\n",
      "\n",
      "Partition: 80/20\n",
      "  Avg Train Accuracy: 1.0000\n",
      "  Avg CV Accuracy: 0.9692\n",
      "  Avg Test Accuracy: 0.9649\n",
      "\n",
      "results saved to xgboost_results.csv successfully!\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
